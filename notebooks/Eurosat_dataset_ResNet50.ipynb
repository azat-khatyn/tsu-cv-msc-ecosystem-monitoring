{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO9VhSrJWAGS"
      },
      "source": [
        "**Содержание**\n",
        "\n",
        "Этот набор данных содержит изображения, относящиеся к набору данных EuroSat. В нём есть 2 папки, а именно:\n",
        "\n",
        "EuroSAT → Содержит изображения RGB, собранные из набора данных Sentinel.\n",
        "\n",
        "EuroSATallBands → Содержит файлы .tif, в которых представлены все диапазоны спектра, собранные со спутника Sentinel-2.\n",
        "\n",
        "Каждое изображение имеет размер 64x64 пикселя с шагом 10 м. Все они были получены со спутника Sentinel-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77Xg1Xn1TCjy",
        "outputId": "668b80d3-117f-4e0e-bda0-4094780f55ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import kagglehub\n",
        "from PIL import ImageFile, Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxJgJzYsc8_w"
      },
      "source": [
        "Мне необходима именно папка Forest, потому что до этого я пыталась обучить на всех данных и у меня ушло 12 часов только на 3 эпохи... Решила сократить."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9oLuEvMcDmb",
        "outputId": "abd5939d-65a1-4980-8860-22008294dcd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/apollo2506/eurosat-dataset?dataset_version_number=6...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2.04G/2.04G [00:24<00:00, 89.2MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "path = kagglehub.dataset_download(\"apollo2506/eurosat-dataset\")\n",
        "forest_path = \"/root/.cache/kagglehub/datasets/apollo2506/eurosat-dataset/versions/6/EuroSAT/Forest\"\n",
        "new_forest_path = os.path.join(forest_path, \"forest\")  # Создаем подпапку \"forest\"\n",
        "\n",
        "os.makedirs(new_forest_path, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(forest_path):\n",
        "        try:\n",
        "            shutil.move(os.path.join(forest_path, filename), new_forest_path)  # Перемещаем файлы\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка перемещения файла {filename}: {e}\")\n",
        "\n",
        "            forest_path = os.path.join(dataset_path, \"EuroSAT\", \"Forest\", \"forest\") # Путь к подпапке \"forest\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6AJ0NMhbp8F",
        "outputId": "a60e958b-db93-4e2f-f554-d4202444e80b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Классы: ['forest']\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(root=forest_path, transform=transform)\n",
        "val_data = datasets.ImageFolder(root=forest_path, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Классы: {train_data.classes}\") # Forest\n",
        "num_classes = len(train_data.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry3yAHQ7RoKr",
        "outputId": "22f40735-2210-4072-f015-02caf81b8b64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 98.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Определение устройства (GPU или CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Загрузка предобученной модели ResNet50\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "\n",
        "# Заморозка весов предобученной части модели\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Замена последнего слоя на новый с одним выходом (для бинарной классификации)\n",
        "model.fc = nn.Linear(model.fc.in_features, 1)\n",
        "\n",
        "# Перемещение модели на устройство\n",
        "model = model.to(device)\n",
        "\n",
        "# Определение функции потерь и оптимизатора\n",
        "criterion = nn.BCEWithLogitsLoss()  # Бинарная кросс-энтропия\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "i55yQO8-RrDZ",
        "outputId": "1fbddd3f-0723-439c-e1c4-fd6743fb3ae9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.05800846001093692\n",
            "Epoch 2, Loss: 0.006273643004688177\n",
            "Epoch 3, Loss: 0.003528203444921986\n",
            "Epoch 4, Loss: 0.002352270727452049\n",
            "Epoch 5, Loss: 0.0018778150198991074\n",
            "Epoch 6, Loss: 0.0013437407447936687\n",
            "Epoch 7, Loss: 0.0011011943325742169\n",
            "Epoch 8, Loss: 0.0009718899555662845\n",
            "Epoch 9, Loss: 0.0007596531922512866\n"
          ]
        }
      ],
      "source": [
        "# Количество эпох\n",
        "num_epochs = 10\n",
        "\n",
        "# Обучение модели\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "print(\"Training Finished!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKxEkopHRse8",
        "outputId": "6654980e-cc44-4174-daee-a159a4468865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model is saved!\n"
          ]
        }
      ],
      "source": [
        "# Сохранение весов модели\n",
        "torch.save(model.state_dict(), \"forest_resnet50.pth\")\n",
        "print(\"The model is saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjAS4cFwRt0C",
        "outputId": "022df1ca-e07c-4b38-fb77-d8010533551f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Рекомендация: Полностью здоровый лес (уверенность: 100.0%).\n"
          ]
        }
      ],
      "source": [
        "# Список возможных состояний леса\n",
        "forest_states = [\n",
        "    \"Полностью здоровый лес\",\n",
        "    \"Лес с небольшими проблемами (небольшие участки вырубки, признаки болезней)\",\n",
        "    \"Лес с умеренными проблемами (заметные участки вырубки, распространение болезней)\",\n",
        "    \"Лес с серьезными проблемами (значительные вырубки, массовые заболевания)\",\n",
        "    \"Лес, требующий немедленного восстановления (практически полное отсутствие растительности)\"\n",
        "]\n",
        "\n",
        "def predict_forest_state(image_path): # Предсказывает состояние леса на основе изображения.\n",
        "\n",
        "    # Загрузка и преобразование изображения\n",
        "    image = Image.open(image_path).convert(\"RGB\") # Важно преобразовать в RGB\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Предсказание\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "\n",
        "        # Предполагаем, что модель возвращает вероятности для каждого класса forest_states\n",
        "        probabilities = torch.softmax(output, dim=1) # Применяем softmax, чтобы получить вероятности\n",
        "        predicted_class = torch.argmax(probabilities).item() # Получаем индекс класса с наибольшей вероятностью\n",
        "        confidence = probabilities[0][predicted_class].item() # Получаем уверенность в предсказании\n",
        "\n",
        "    # Формирование рекомендаций\n",
        "    state = forest_states[predicted_class]\n",
        "    confidence_percentage = round(confidence * 100, 2)\n",
        "    recommendation = f\"Рекомендация: {state} (уверенность: {confidence_percentage}%).\"\n",
        "\n",
        "    # Дополнительные рекомендациит:\n",
        "    if \"вырубки\" in state.lower():\n",
        "        recommendation += \" Рекомендуется провести мониторинг участков вырубки и принять меры по лесовосстановлению.\"\n",
        "    elif \"болезни\" in state.lower():\n",
        "        recommendation += \" Необходима проверка на наличие заболеваний и принятие мер по их лечению.\"\n",
        "    elif confidence < 0.7:\n",
        "        recommendation = f\"Недостаточная уверенность в оценке. Рекомендуется дополнительный анализ.\"\n",
        "    return recommendation\n",
        "\n",
        "# Пример использования функции\n",
        "image_path = \"felled_forest.jpg\"\n",
        "print(predict_forest_state(image_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Это лишь набросок рекомендаций. Но чтобы рекомендации были более точными, можно добавить анализ дополнительных параметров:\n",
        "\n",
        "Площадь поражения;\n",
        "площадь вырубки или деградации;\n",
        "Интенсивность изменений. Например, если модель может определить степень деградации (слабая, средняя, сильная), рекомендации можно адаптировать под это;\n",
        "Временные изменения. Отследить динамику изменений (например, скорость вырубки или восстановления).\n",
        "Но отсюда и проблема... Сложно получить спутниковые снимки с временными рядами и дообучить модель. Было бы здорово дообучить её на данных, которые включают:\n",
        "\n",
        "Метки классов с дополнительной информацией. Например, не просто \"Лес\", а \"Лес с хорошим покровом\", \"Лес деградированный\", \"Лес после пожара\" (как раз с этого и начали).\n",
        "\n",
        "И уже для каждого класса можно добавить текстовое описание рекомендаций, и модель сможет учиться предсказывать их напрямую. Например, \"Лес в хорошем состоянии. Рекомендуется продолжить мониторинг.\", \"Лес деградирован. Рекомендуется восстановить растительный покров.\", \"Обнаружены следы пожаров. Необходимо восстановить экосистему.\".\n",
        "\n",
        "Но нужны хорошие размеченные данные...\n",
        "\n",
        "Если совсем далеко заглядывать, то в дальнейшем наладить механизм обратной связи: Пользователь (например, эколог или лесник) может оценить, насколько рекомендации были полезны. Эти данные можно использовать для дальнейшего дообучения модели."
      ],
      "metadata": {
        "id": "DONvVDxzgUnJ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}