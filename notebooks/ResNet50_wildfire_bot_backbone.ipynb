{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BIrTji-eLOgZ",
    "outputId": "edba9f5b-185a-4b9d-eaff-e0ddd5fccb46"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.3 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import opendatasets as od  # Библиотека для загрузки датасетов с Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cufz9IgRLOi5",
    "outputId": "97f495f3-d217-443a-d4a8-6b9a3baf4db8"
   },
   "outputs": [],
   "source": [
    "# !pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qg0U4fbhLOna",
    "outputId": "4827745f-176a-4ca3-c108-5bcc523d0b68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Проверка доступности GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upSSCOWfLh6j"
   },
   "outputs": [],
   "source": [
    "# Загрузка датасета с Kaggle\n",
    "dataset_url = \"https://www.kaggle.com/datasets/elmadafri/the-wildfire-dataset\"\n",
    "dataset_path = \"/content/the-wildfire-dataset/the_wildfire_dataset_2n_version\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ys6eBK_0LOpp",
    "outputId": "e6f80f0e-6518-41f6-e479-07310560e301"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:Your Kaggle Key:Dataset URL: https://www.kaggle.com/datasets/elmadafri/the-wildfire-dataset\n",
      "Downloading the-wildfire-dataset.zip to ./the-wildfire-dataset\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.94G/9.94G [02:12<00:00, 80.3MB/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Скачиваем датасет, если он еще не скачан\n",
    "if not os.path.exists(dataset_path):\n",
    "    od.download(dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XHrdAG4mLOr4",
    "outputId": "e31f31ed-feeb-4b29-b0fa-4cd3745c5d7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Содержимое папки датасета:\n",
      "['test', 'train', 'val']\n"
     ]
    }
   ],
   "source": [
    "# Проверка структуры датасета\n",
    "print(\"Содержимое папки датасета:\")\n",
    "print(os.listdir(dataset_path))\n",
    "\n",
    "# Пути к данным\n",
    "train_path = os.path.join(dataset_path, \"train\")\n",
    "val_path = os.path.join(dataset_path, \"val\")\n",
    "test_path = os.path.join(dataset_path, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2-psGAELOuL"
   },
   "outputs": [],
   "source": [
    "# Проверка существования папок\n",
    "if not os.path.exists(train_path):\n",
    "    raise FileNotFoundError(f\"Папка train не найдена: {train_path}\")\n",
    "if not os.path.exists(val_path):\n",
    "    raise FileNotFoundError(f\"Папка val не найдена: {val_path}\")\n",
    "if not os.path.exists(test_path):\n",
    "    raise FileNotFoundError(f\"Папка test не найдена: {test_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KaSH1MyPLOwq"
   },
   "outputs": [],
   "source": [
    "# Определение аугментаций с использованием albumentations\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),  # Случайное изменение размера и обрезка\n",
    "    A.HorizontalFlip(p=0.5),  # Горизонтальное отражение с вероятностью 50%\n",
    "    A.Rotate(limit=30, p=0.5),  # Поворот на угол до 30 градусов\n",
    "    A.RandomBrightnessContrast(p=0.2),  # Случайное изменение яркости и контраста\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Нормализация\n",
    "    ToTensorV2(),  # Преобразование в тензор\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),  # Простое изменение размера для валидации\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Нормализация\n",
    "    ToTensorV2(),  # Преобразование в тензор\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUlTvAtWL3Q-"
   },
   "outputs": [],
   "source": [
    "# Создание пользовательского Dataset\n",
    "class WildfireDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.transform = transform\n",
    "        self.classes = [d for d in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, d))]  # Список классов (папок)\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Собираем пути к изображениям и метки\n",
    "        for class_name in self.classes:\n",
    "            class_path = os.path.join(folder_path, class_name)\n",
    "            for img_name in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                # Пропускаем директории и файлы, которые не являются изображениями\n",
    "                if os.path.isfile(img_path) and img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(self.classes.index(class_name))\n",
    "                else:\n",
    "                    print(f\"Ignoring non-image file or directory: {img_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            label = self.labels[idx]\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image=np.array(image))[\"image\"]\n",
    "\n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QDbUfxW_L3UD",
    "outputId": "6e947093-2da1-4c9d-c1b7-d00ccee6acd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring non-image file or directory: /content/the-wildfire-dataset/the_wildfire_dataset_2n_version/val/fire/desktop.ini\n"
     ]
    }
   ],
   "source": [
    "# Создание DataLoader\n",
    "train_dataset = WildfireDataset(train_path, transform=train_transform)\n",
    "val_dataset = WildfireDataset(val_path, transform=val_transform)\n",
    "test_dataset = WildfireDataset(test_path, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HnFliHjOL3WP",
    "outputId": "309d5f1a-ed89-4260-e7fb-f5f8969c80c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:01<00:00, 54.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Загрузка предобученной модели ResNet50\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Замена классификатора\n",
    "num_classes = len(train_dataset.classes)  # Количество классов\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Перемещение модели на устройство\n",
    "model = model.to(device)\n",
    "\n",
    "# Оптимизатор и функция потерь\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H-HzO4TNM5To",
    "outputId": "2bcd090a-fae7-462e-c84a-9b472a93cf5a"
   },
   "outputs": [],
   "source": [
    "# Обучение модели\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Оценка модели на валидационной выборке\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R9fCtLUd981r",
    "outputId": "0403bbfc-45dc-4496-b23c-e8f1354679ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 91.04%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        if images is None or labels is None:\n",
    "            continue  # Пропускаем проблемные данные\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Оценка модели на тестовой выборке\n",
    "correct = 0\n",
    "total = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pAtrgBAkLOy7",
    "outputId": "f651cd1a-2b59-4f65-edeb-2e2ff784d3ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3402: DecompressionBombWarning: Image size (101859328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3402: DecompressionBombWarning: Image size (94487082 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3402: DecompressionBombWarning: Image size (96631920 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.39%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        if images is None or labels is None:\n",
    "          continue  # Пропускаем проблемные данные\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUbGQgSx-Ga9"
   },
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "torch.save(model.state_dict(), \"resnet50_wildfire.pth\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
